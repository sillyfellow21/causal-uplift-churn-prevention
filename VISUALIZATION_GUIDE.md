# üìä Visualization Guide - Expected Outputs

This document shows what visualizations will be generated when you run the scripts.

## Core Model Visualizations

### 1. qini_curve_profitability.png
**Generated by:** `evaluate_uplift_model.py`

**Description:** Two-panel visualization showing model performance and optimal targeting strategy

**Left Panel - Qini Curve:**
- **Blue solid line:** Uplift model cumulative gains
- **Red dashed line:** Random targeting baseline
- **Green shaded area:** Model improvement over random
- **X-axis:** % of population targeted (0-100%)
- **Y-axis:** Cumulative incremental visits gained

**Right Panel - Profitability Analysis:**
- **Blue line with circles:** Profit at each targeting level (10%, 20%, ... 100%)
- **Red dashed line:** Baseline profit (target everyone)
- **Green star:** Optimal point (80% targeting, max profit $59,993)
- **X-axis:** % of population targeted
- **Y-axis:** Net profit ($)

**Key Insight:** Shows optimal strategy is targeting top 80% by uplift score

---

### 2. strategic_quadrants.png
**Generated by:** `evaluate_uplift_model.py`

**Description:** Two-panel visualization showing customer segmentation

**Left Panel - Scatter Plot:**
- **X-axis:** P(visit | control) - baseline engagement
- **Y-axis:** P(visit | treatment) - response to campaign
- **Green dots:** Persuadables (low baseline, high response) ‚úÖ TARGET
- **Blue dots:** Sure Things (high baseline, high response) ‚ö™ Optional
- **Gray dots:** Lost Causes (low baseline, low response) ‚ö™ Skip
- **Red dots:** Sleeping Dogs (high baseline, low response) ‚ùå AVOID
- **Black dashed lines:** Median thresholds separating quadrants

**Right Panel - Bar Chart:**
- Shows count and percentage of each segment
- Color-coded by segment (green/blue/gray/red)
- Labels show both absolute count and percentage
- Typical distribution: 11.7% Persuadables, 38.3% Sure Things, 38.3% Lost Causes, 11.7% Sleeping Dogs

**Key Insight:** Visually demonstrates the four strategic customer types

---

## Advanced Visualizations ‚≠ê

### 3. metalearner_comparison.png
**Generated by:** `compare_metalearners.py`

**Description:** Four-panel systematic comparison of S/T/X-Learner approaches

**Top-Left Panel - Qini Curves:**
- **Blue:** S-Learner (single model, treatment as feature)
- **Green:** T-Learner (two models, separate control/treatment)
- **Orange:** X-Learner (advanced, imputed counterfactuals)
- **Red dashed:** Random baseline
- Shows which meta-learner performs best overall

**Top-Right Panel - Uplift @ Top K:**
- Grouped bar chart comparing precision at top 10%, 20%, 50%
- Three bars per group (S/T/X-Learner)
- Shows which model best identifies high-uplift users

**Bottom-Left Panel - Uplift Distributions:**
- Overlapping histograms of uplift scores from each model
- S-Learner (blue), T-Learner (green), X-Learner (orange)
- Red vertical line at zero uplift
- Shows spread and range of predictions

**Bottom-Right Panel - Metrics Comparison:**
- Grouped bar chart of normalized metrics
- Qini Coefficient, AUUC, Uplift@10%
- Direct visual comparison of performance

**Key Insight:** T-Learner typically wins on Qini, X-Learner on top-decile precision

---

### 4. shap_summary_uplift.png
**Generated by:** `explainability_shap.py`

**Description:** SHAP summary plot showing global feature importance for uplift

**Layout:**
- **Y-axis:** Features ranked by importance (top to bottom)
- **X-axis:** SHAP value (impact on uplift score)
- **Color:** Feature value (red = high, blue = low)
- **Dots:** Individual predictions (one per user)
- **Density:** How many users have that feature/impact combination

**Key Patterns to Look For:**
- High `history` (red) ‚Üí negative SHAP (pushes left) = Sleeping Dogs
- Low `recency` (blue) ‚Üí positive SHAP (pushes right) = Persuadables
- Shows which features drive uplift and in what direction

**Key Insight:** Reveals the causal drivers of treatment heterogeneity

---

### 5. shap_individual_explanations.png
**Generated by:** `explainability_shap.py`

**Description:** Two waterfall plots explaining individual predictions

**Left Panel - Persuadable Example:**
- **Base value:** 0 (starting point)
- **Red bars:** Features increasing uplift
- **Blue bars:** Features decreasing uplift
- **Final value:** Total uplift score (e.g., +0.1236)
- Shows why this user responds well to campaigns

**Right Panel - Sleeping Dog Example:**
- Same format as left panel
- **Final value:** Low/negative uplift (e.g., +0.0080)
- Shows why campaigns backfire for this user (e.g., high baseline activity)

**Key Insight:** Provides explainable reasoning for each targeting decision

---

### 6. shap_feature_interactions.png
**Generated by:** `explainability_shap.py`

**Description:** Two dependence plots showing feature interactions

**Left Panel - Top Feature (e.g., `history`):**
- **X-axis:** Feature value (purchase history amount)
- **Y-axis:** SHAP value (impact on uplift)
- **Color:** Interaction with second feature (e.g., `recency`)
- Shows non-linear effects and interaction patterns

**Right Panel - Second Feature (e.g., `recency`):**
- **X-axis:** Days since last purchase
- **Y-axis:** SHAP value
- **Color:** Interaction with first feature
- Reveals how features combine (e.g., low recency + low history = high uplift)

**Key Insight:** Uncovers complex interactions that drive treatment effects

---

### 7. shap_by_segment.png
**Generated by:** `explainability_shap.py`

**Description:** Four bar charts showing segment-specific feature importance

**Four Panels (one per segment):**
1. **Persuadables (green):** Top 10 features driving high uplift
2. **Sure Things (blue):** Features common to high engagement
3. **Lost Causes (gray):** Features predicting low engagement
4. **Sleeping Dogs (red):** Features where campaigns backfire

**Each Panel Shows:**
- Horizontal bars ranked by mean absolute SHAP value
- Top 10 most important features for that segment
- Enables targeted messaging strategies

**Key Insight:** Different segments respond to different features - enables personalization

---

## Visualization Summary Table

| Visualization | Type | Purpose | Key Metric | Generated By |
|--------------|------|---------|------------|--------------|
| `qini_curve_profitability.png` | Line charts | Model performance & ROI | Qini: 0.0556 | evaluate_uplift_model.py |
| `strategic_quadrants.png` | Scatter + Bar | Customer segmentation | 4 segments | evaluate_uplift_model.py |
| `metalearner_comparison.png` ‚≠ê | 4-panel grid | Meta-learner evaluation | Qini, AUUC, Uplift@K | compare_metalearners.py |
| `shap_summary_uplift.png` ‚≠ê | Beeswarm plot | Global feature importance | Top drivers | explainability_shap.py |
| `shap_individual_explanations.png` ‚≠ê | Waterfall plots | Individual predictions | User-level why | explainability_shap.py |
| `shap_feature_interactions.png` ‚≠ê | Dependence plots | Feature interactions | Non-linear effects | explainability_shap.py |
| `shap_by_segment.png` ‚≠ê | 4 bar charts | Segment-specific drivers | Personalization | explainability_shap.py |

**‚≠ê = Advanced visualizations that differentiate this project**

---

## How to Generate Visualizations

### Step 1: Run Core Pipeline
```bash
python hillstrom_analysis.py      # Preprocessing
python uplift_t_learner.py        # Model training
python evaluate_uplift_model.py   # Generate qini & quadrants
```

### Step 2: Run Advanced Analysis
```bash
python compare_metalearners.py    # Generate meta-learner comparison
python explainability_shap.py     # Generate all SHAP visualizations
```

### Step 3: Verify Outputs
```powershell
Get-ChildItem *.png | Select-Object Name, @{Name="Size";Expression={"{0:N0} KB" -f ($_.Length/1KB)}}
```

Expected files:
- qini_curve_profitability.png (~252 KB)
- strategic_quadrants.png (~705 KB)
- metalearner_comparison.png (~800 KB)
- shap_summary_uplift.png (~600 KB)
- shap_individual_explanations.png (~500 KB)
- shap_feature_interactions.png (~450 KB)
- shap_by_segment.png (~700 KB)

---

## For Portfolio/GitHub

**Recommendation:** Include all visualizations in your README with descriptions

**Screenshot Strategy:**
1. **Hero image:** `metalearner_comparison.png` - shows depth
2. **Business value:** `qini_curve_profitability.png` - shows ROI
3. **Explainability:** `shap_individual_explanations.png` - shows interpretability
4. **Segmentation:** `strategic_quadrants.png` - shows strategy

These 4 images tell the complete story: systematic approach, business impact, interpretability, actionable insights.

---

## Interview Prep: How to Present

### When showing visualizations in interview:

**"Let me walk you through my systematic approach..."**

1. **Start with metalearner_comparison.png:**
   "I didn't just use T-Learner. I compared S, T, and X-Learner systematically using Qini, AUUC, and Uplift@K metrics. T-Learner won overall but X-Learner had better top-decile precision."

2. **Show SHAP explainability:**
   "For production ML, interpretability is critical. Here's why this user is a Persuadable [show waterfall]. Purchase history and recency drive the uplift. This enables explainable targeting decisions."

3. **Highlight business impact:**
   "The Qini curve shows the model outperforms random targeting. The profitability analysis identified 80% as optimal targeting, improving ROI by 85 percentage points."

4. **Demonstrate strategic thinking:**
   "Strategic quadrants segment users into four groups. The key insight: 11.7% are Sleeping Dogs where campaigns backfire. Traditional models miss this completely."

This demonstrates: technical depth, production thinking, business acumen, and communication skills.
